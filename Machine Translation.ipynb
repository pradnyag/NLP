{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZfqzG-psHbd"
      },
      "source": [
        "#**Lab 5 and 6: Neural Machine Translation (Extra Guide)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GBwu1PsSR3"
      },
      "source": [
        "This week and the next, we'll be build a neural machine translation model based on the sequence-to-sequence (seq2seq) models proposed by Sutskever et al., 2014 and Cho et al., 2014. The seq2seq model is widely used in machine translation systems such as Google’s neural machine translation system (GNMT) (Wu et al., 2016).\n",
        "\n",
        "A folder, **nmt_lab_files** has been provided for you. This folder contains 3 files:\n",
        "1. **data.30.vi** - a file. each line of the file contains a Vietnamese sentence to be translated (i.e. the source sentences)\n",
        "2. **data.30.en** - a file. each line of the file contains an English sentence corresponding to the Vietnamese sentence in the same line position. (i.e. the target sentences)\n",
        "3. **nmt_model_keras.py** - the incomplete code for this lab.\n",
        "\n",
        "The doc file provided contains an explanation of the code file and a guide on how to complete the code (by doing 3 tasks). Read the doc file and if you can, complete the code as instructed. When the code is completed, skip to section xx of this notebook. \n",
        "\n",
        "This notebook (prior to section section xx) merely contains further explanation on sections of the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyDvxbvTt70n"
      },
      "source": [
        "##**LanguageDict**\n",
        "\n",
        "LanguageDict is a class for creating language dict objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtHvI1pGvMBG"
      },
      "source": [
        "##**The <load_dataset()> Method**\n",
        "\n",
        "This helper method reads from the source and target files to \n",
        "- load max_num_examples sentences, \n",
        "- split the sentences them into train, development and testing, and\n",
        "- return relevant data.\n",
        "The code for this is fully commented. \n",
        "\n",
        "<br>\n",
        "\n",
        "As an example to the kind of ouput returned by this model, let's assume we are translating the sentence 'I like dogs' from English to English (this of course is never the case), such that the tokenized and case normalized source sentence list and target sentence list are as follows:\n",
        "\n",
        "\n",
        "```\n",
        "# In our case this would actually be [['tôi', 'thích', 'thỏ']], i.e the Vietnamese equivalent of the English sentence. \n",
        "# We've used English to English here so we can follow along with the code.\n",
        "source_words = [['i', 'like', 'rabbits']] \n",
        "target_words = [['i', 'like', 'rabbits']]\n",
        "```\n",
        "The word2ids for the source and target language dictionaries would look something like:\n",
        "```\n",
        "source_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, 'i': 2, 'like': 3, 'rabbits':4}\n",
        "\n",
        "# end and start tokens are added for the target words\n",
        "target_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, '<start>': 2, 'i': 3, 'like': 4, 'rabbits':5, '<end>':6}\n",
        "\n",
        "```\n",
        "Let's also assume that we are training and testing on this same dataset of one sentence.\n",
        "The **source words** for train/dev/test will be given as\n",
        "```\n",
        "# a batch_size X max_sent_length array.\n",
        "source_words_train = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
        "source_words_dev = [[2,3,4]]  # corresponding to ['i', 'like', 'rabbits']\n",
        "source_words_test = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
        "```\n",
        "\n",
        "The **target words** for train data will be given as follows (dev/test don't need target words as the model will provide this):\n",
        "```\n",
        "target_words_train = [[2,3,4,5]] # corresponding to ['<start>', 'i', 'like', 'rabbits']\n",
        "```\n",
        "\n",
        "The **target words labels** for each word will be the word after it. The target word labels for train/dev/test data will be given as follows\n",
        "```\n",
        "target_words_train_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "target_words_dev_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "target_words_test_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "```\n",
        "The dimensions for train target words labels would be expanded to this:\n",
        "`[[3], [4], [5], [6]]`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8KZaJn3uBK"
      },
      "source": [
        "##**The Neural Translation Model (NMT)**\n",
        "\n",
        "For the NMT the network (a system of connected layers/models) used for training differs slightly from the network used for inference. Both use the the seq-to-seq encoder-decoder architecture. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgtz6XAl4E8D"
      },
      "source": [
        "###**The training mode**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "Given:\n",
        "- `source_words`: a `batch_size(num_sents) x max_sentence_length` array representing the source words. In our mini example, this would be the Vietnamese equivalent of `['i', 'like', 'rabbits']`; `[['tôi', 'thích', 'thỏ']]`\n",
        "\n",
        "The following steps comprise the encoding network:\n",
        "\n",
        "1. transform `source_words` into `source_words_embeddings` using a randomly initialized embedding lookup. source_words_embeddings is thus a `batch_size(num_sents) x max_sentence_length x embedding_dim` array.\n",
        "2. Apply embedding dropout of `embedding_dropout_rate`.\n",
        "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the source words i.e. to encode the input. \n",
        "\n",
        "    (a.) The hidden and cell states for this `LSTM` are initialized to zeros (i.e. we leave the `initial_states = None` default as is).\n",
        "\n",
        "    (b.) We save the `encoder_output` (the sequence not just the last state); and the encoder (hidden and cell) states. \n",
        "\n",
        "This way, the model encodes a representation for the source words. Task 1 guides you to complete the encoder part of the training model.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Decoder (No Attention)**\n",
        "\n",
        "Given:\n",
        "- `target_words`: a `batch_size(i.e.num_sents in batch) x max_sentence_length+1` array representing the target words. This is a time shifted translation of the source words with an added (prepended) `<START>` token `['<start>', 'i', 'like', 'rabbits']`.\n",
        "\n",
        "The decoding is in the following steps:\n",
        "\n",
        "1. transform `target_words` into `target_words_embeddings` using a randomly initialized embedding lookup. target_words_embeddings is thus a `batch_size x max_sentence_length+1 x embedding_dim` array.\n",
        "\n",
        "2.  Apply embedding dropout of `embedding_dropout_rate`.\n",
        "\n",
        "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the target words. Some context is given to this model by using the encoder states to initialize the decoder lstm. This way the encoder state for `'tôi'` for example is used to learn to the representation (and next word prediction, see number 4.) for the `'<start>'` token, and so on.\n",
        "\n",
        "4. For each token representation, use a dense layer to predict a `target_vocab_size` vector which is the probability that any given word in the target vocabulary is the next word following the represented token. The output `decoder_outputs_train` is thus a `batch_size x max_sent_length x target_vocab_size` array.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4tsMpCYJUk1"
      },
      "source": [
        "###**The Inference Mode**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "The inference time encoding follows the same steps as training time encoding.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Decoder (No attention)**\n",
        "\n",
        "During training time, we passed a `batch_size(num_sents) x max_sentence_length` array representing the target words into the decoder lstm. The decoder_lstm learns how to represent a given target sentence using the context from the encoder lstm (that learns to represent a source sentence).  \n",
        "\n",
        "At test time, several things are different:\n",
        "\n",
        "1. We no longer have access to a complete translation of the source sentence (recall that no target_words array exists for dev and test sets). Rather, we initialize the target_words_array as thus:\n",
        "\n",
        "    Each expected sentence contains only a single token index, the index of the `'<start>'` token. So, the target_word_dev/test is a `batch_size x 1` array. (see the nmt.eval() function for this)\n",
        "\n",
        "2. This `batch_size x 1` array is fed to the trained decoder_lstm and the predicted array is a `batch_size x 1 x target_vocab_size` such that taking the argmax of this array accross the dimension 2 will give the most probable next word. \n",
        "\n",
        "    For example, at time_step `0`, the first time step, where the `step_target_words` given is the `batch_size x 1` array containing the `'<start>'` token, the next word prediction of the decoder is for each sentence (in the batch) the initial word in the sentence. \n",
        "\n",
        "3. At the first time step, the decoder_lstm still uses the encoder_states as it's initial states. At subsequent time steps, it uses it's own states from the previous time steps. This is also what the decoder_lstm does at training time but it is made more explicit here as we loop over time steps using a for loop.\n",
        "(see nmt.eval())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-fQvjrBBQwI"
      },
      "source": [
        "###**Task 1**    \n",
        "    \"\"\"\n",
        "    Task 1 encoder\n",
        "    \n",
        "    Start\n",
        "    \"\"\"\n",
        "    # The train encoder\n",
        "    # (a.) Create two randomly initialized embedding lookups, one for the source, another for the target. \n",
        "    print('Task 1(a): Creating the embedding lookups...')\n",
        "   \n",
        "    embeddings_source = Embedding(input_dim=self.vocab_source_size, embeddings_initializer='random_uniform', mask_zero=True, output_dim=self.embedding_size,input_length=source_words.shape[1])\n",
        "    embeddings_target = Embedding(input_dim=self.vocab_target_size, embeddings_initializer='random_uniform', mask_zero=True, output_dim=self.embedding_size,input_length=target_words.shape[1])\n",
        "\n",
        "    '''Created two Embedding layers embedding_source and embedding_target which will randomly initialize the embeddings for individual words in the vocabulary (the embeddings will be trained during the training). \n",
        "    The Embedding layers have an input_dim of the vocab_size and a output_dim of the embedding_size.\n",
        "    Also, mask_zero is set to True in order to get rid of the paddings. '''\n",
        "\n",
        "    # (b.) Look up the embeddings for source words and for target words. Apply dropout to each encoded input\n",
        "    print('\\nTask 1(b): Looking up source and target words...')\n",
        "    source_words_embeddings = embeddings_source(source_words)\n",
        "    source_words_embeddings = Dropout(self.embedding_dropout_rate)(source_words_embeddings)\n",
        "\n",
        "    target_words_embeddings = embeddings_target(target_words)\n",
        "    target_words_embeddings = Dropout(self.embedding_dropout_rate)(target_words_embeddings)\n",
        "    \n",
        "    '''\n",
        "    Created embeddings for the current inputs (source_words and target_words) by passing them through the Embedding layers. \n",
        "    The embeddings for source and target words are called source_words_embeddings and target_words_embeddings respectively. \n",
        "    Dropout is applied to the embeddings by using the Dropout layers. \n",
        "    The dropout rate for the word embeddings is called embedding_dropout_rate. \n",
        "    '''\n",
        "    # (c.) An encoder LSTM() with return sequences set to True\n",
        "    print('\\nTask 1(c): Creating an encoder')\n",
        "    encoder_lstm = LSTM(self.hidden_size,recurrent_dropout=self.hidden_dropout_rate,return_sequences=True,return_state=True)\n",
        "    encoder_outputs,encoder_state_h,encoder_state_c = encoder_lstm(source_words_embeddings)\n",
        "\n",
        "    '''\n",
        "    Created a LSTM layer to process the source_words_embeddings, with return_sequences set to True to get the outputs for all tokens (call it encoder_outputs) \n",
        "    and return_state set to True to get the hidden state (encoder_state_h) and cell state (encoder_state_c) from the encoder LSTM. \n",
        "    '''\n",
        "    \"\"\"\n",
        "    End Task 1\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFIKOF5sed68"
      },
      "source": [
        "##**Training Without Attention**\n",
        "\n",
        "If you've completed Tasks 1 and 2, you are ready to train the NMT model without attention.\n",
        "\n",
        "Run the following cells to train the model for 10 epochs. It also shows the model summary of the each model you encapsulated.\n",
        "\n",
        "If you're using a GPU, training will no more than 10 minutes and you will get a BLEU score between 4 and 5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V5YoFP3yQO-",
        "outputId": "3522a46e-740d-40fa-8eef-867798534e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "upXa_erqyzKm"
      },
      "outputs": [],
      "source": [
        "# change this to the path to your folder. Remember to start from the home directory\n",
        "PATH = 'My Drive/Colab Notebooks/NN NLP/Labs 5 and 6 Neural Machine Traslation with and without attention-20220313/nmt_lab_files/' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ffbGcgrRy7p6"
      },
      "outputs": [],
      "source": [
        "PATH_TO_FOLDER = \"/content/drive/\" + PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XfSgKakK0QgV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(PATH_TO_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NmSgv44y0TN9"
      },
      "outputs": [],
      "source": [
        "SOURCE_PATH = PATH_TO_FOLDER + 'data.30.vi'\n",
        "TARGET_PATH = PATH_TO_FOLDER + 'data.30.en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OOTMtc_l0_ut"
      },
      "outputs": [],
      "source": [
        "import nmt_model_keras as nmt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr4ZqoioE_S8"
      },
      "source": [
        "###**Task 2**\n",
        "    \n",
        "    Task 2 decoder for inference\n",
        "    \n",
        "    Start\n",
        "    \"\"\"\n",
        "    # Task 1 (a.) Get the decoded outputs\n",
        "    print('\\n Putting together the decoder states')\n",
        "    # get the inititial states for the decoder, decoder_states\n",
        "    \n",
        "    # decoder states are the hidden and cell states from the training stage\n",
        "    decoder_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    '''The states passed to the decoder_model  decoder_state_input_h and decoder_state_input_c are put together to create a list decoder_states. '''\n",
        "    \n",
        "    # use decoder states as input to the decoder lstm to get the decoder outputs, h, and c for test time inference\n",
        "    decoder_outputs_test,decoder_state_output_h, decoder_state_output_c = decoder_lstm(target_words_embeddings,initial_state=decoder_states)\n",
        "\n",
        "    '''The target_word_embeddings and decoder_states are passed on to the decoder_lstm.''' \n",
        "\n",
        "    # Task 1 (b.) Add attention if attention\n",
        "    if self.use_attention:\n",
        "        decoder_attention = AttentionLayer()\n",
        "        decoder_outputs_test = decoder_attention([encoder_outputs_input,decoder_outputs_test])\n",
        "\n",
        "    '''If statement for the attention model similar as the decoder for training. '''\n",
        "\n",
        "    # Task 1 (c.) pass the decoder_outputs_test (with or without attention) to the decoder dense layer\n",
        "    decoder_outputs_test = decoder_dense(decoder_outputs_test) \n",
        "\n",
        "    '''Passed the output of the attention layer (for attention model) into the final layer of the decoder (decoder_dense) to assign probabilities of the next tokens. '''\n",
        "    \n",
        "    \"\"\"\n",
        "    End Task 2 \n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y6RhIYFGyYj",
        "outputId": "c6da910f-a35f-4486-cdc6-9df69d617d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dictionaries\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 100)    203400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    250600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 100)    0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 100)    0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, None, 200),  240800      ['dropout[0][0]']                \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  240800      ['dropout_1[0][0]',              \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2506)   503706      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,439,306\n",
            "Trainable params: 1,439,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         203400    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 100)         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 444,200\n",
            "Trainable params: 444,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    250600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 100)    0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  240800      ['dropout_1[0][0]',              \n",
            "                                 (None, 200),                     'input_3[0][0]',                \n",
            "                                 (None, 200)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, None, 200)]  0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2506)   503706      ['lstm_1[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 995,106\n",
            "Trainable params: 995,106\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 52s 187ms/step - loss: 2.1112 - accuracy: 0.2465\n",
            "Time used for epoch 1: 1 m 26 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "The input sentence:  ['and', 'i', '&apos;m', 'going', 'to', 'be', 'a', '<unk>', '<unk>', ',', 'and', 'we', 'have', 'a', '<unk>', '<unk>', ',', 'and', 'we', 'have', 'to', 'be', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 1.80\n",
            "Time used for evaluate on dev set: 0 m 9 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 45s 187ms/step - loss: 1.8225 - accuracy: 0.3043\n",
            "Time used for epoch 2: 1 m 21 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "The input sentence:  ['it', '&apos;s', 'a', '<unk>', '<unk>', ',', 'and', 'i', 'was', '<unk>', ',', 'and', 'i', 'was', '<unk>', ',', 'and', 'the', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 2.38\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 43s 181ms/step - loss: 1.7138 - accuracy: 0.3314\n",
            "Time used for epoch 3: 1 m 21 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "The input sentence:  ['it', '&apos;s', 'a', '<unk>', '<unk>', ',', 'and', 'i', 'was', '<unk>', 'by', 'the', '<unk>', 'of', 'the', '<unk>', ',', 'and', 'i', 'was', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 3.41\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 44s 184ms/step - loss: 1.6411 - accuracy: 0.3484\n",
            "Time used for epoch 4: 1 m 21 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', '<unk>', ',', 'and', 'it', '&apos;s', '<unk>', ',', 'and', 'it', '&apos;s', '<unk>', ',', 'and', 'the', '<unk>', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 3.72\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 44s 183ms/step - loss: 1.5837 - accuracy: 0.3607\n",
            "Time used for epoch 5: 1 m 21 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "The input sentence:  ['there', 'were', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 4.21\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 44s 183ms/step - loss: 1.5388 - accuracy: 0.3690\n",
            "Time used for epoch 6: 1 m 21 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 4.50\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 44s 185ms/step - loss: 1.5040 - accuracy: 0.3760\n",
            "Time used for epoch 7: 1 m 21 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', '<unk>', ',', 'but', 'it', '&apos;s', 'a', '<unk>', ',', 'and', 'the', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 4.84\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 44s 185ms/step - loss: 1.4747 - accuracy: 0.3801\n",
            "Time used for epoch 8: 1 m 21 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 5.04\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 44s 184ms/step - loss: 1.4527 - accuracy: 0.3840\n",
            "Time used for epoch 9: 1 m 21 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', ',', 'and', 'it', '&apos;s', 'a', '<unk>', '<unk>', ',', 'and', 'the', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 4.94\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 44s 185ms/step - loss: 1.4319 - accuracy: 0.3870\n",
            "Time used for epoch 10: 1 m 22 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', ',', 'and', 'it', '&apos;s', '<unk>', ',', 'and', 'it', '&apos;s', '<unk>', '<unk>', ',', 'and', 'the', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 4.91\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Training finished!\n",
            "Time used for training: 15 m 7 s\n",
            "Evaluating on test set:\n",
            "The input sentence:  ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '.']\n",
            "The output sentence:  [['the', 'second', 'quote', 'is', 'from', 'the', 'head', 'of', 'the', 'u.k.', 'financial', 'services', '<unk>', '.']]\n",
            "source_words: [['trích', 'dẫn', 'thứ', 'hai', 'đến', 'từ', 'người', 'đứng', 'đầu', 'cơ', 'quan', 'quản', 'lý', 'dịch', 'vụ', 'tài', 'chính', 'vương', 'quốc', 'anh', '.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 5.37\n",
            "Time used for evaluate on test set: 0 m 7 s\n"
          ]
        }
      ],
      "source": [
        "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlMDC3DJi12c"
      },
      "source": [
        "##**Decoding with Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cQKwvFqurVY"
      },
      "source": [
        "The inputs to the attention layer are encoder and decoder outputs. The attention mechanism:\n",
        "1. Computes a score (a luong score) for each source word\n",
        "2. Weights the words by their luong scores.\n",
        "3. Concatenates the wieghted encoder representation with the decoder_ouput.\n",
        "This new decoder output will now be the input to the decoder_dense layer. \n",
        "\n",
        "Task 3 description in the doc file outlines the steps for this in detail. Once you have completed this Task, you are now ready to train with attention. Training time will be no more than 10 minutes using a GPU and you should get a bleu score of about 15."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnPA575MPmCQ"
      },
      "source": [
        "###**Task 3**\n",
        "\n",
        "    \"\"\"\n",
        "    Task 3 attention\n",
        "    \n",
        "    Start\n",
        "    \"\"\"\n",
        "    decoder_outputs_temp = K.permute_dimensions(decoder_outputs, (0, 2, 1))\n",
        "    '''Using permute_dimensions method to transpose the last two dimensions of the decoder_outputs to make it shape becomes [batch_size, hidden_size, max_target_sent_len]'''\n",
        "    \n",
        "    luong_score = K.batch_dot(encoder_outputs, decoder_outputs_temp)\n",
        "    '''performed matrix multiplication of inputs encoder_outputs and decoder_outputs to generate the output luong_score with shape of [batch_size, max_source_sent_len, max_target_sent_len].'''\n",
        "\n",
        "    luong_score = K.softmax(luong_score, axis=1)\n",
        "    '''A softmax is applied to the dimension that has a size of max_sourse_sent_len to create an attention score for the encoder_outputs.'''\n",
        "\n",
        "    luong_score = K.expand_dims(luong_score, axis=-1)\n",
        "    encoder_outputs = K.expand_dims(encoder_outputs, axis=2)\n",
        "    encoder_vector = encoder_outputs * luong_score\n",
        "\n",
        "    '''Created the encoder_vector by doing element-wise multiplication between the encoder_outputs and their attention scores (luong_score). \n",
        "    Since, the shape of the luong_score is actually not the same as the encoder_outputs, \n",
        "    used expand_dims method to expand dimensions for both of them. '''\n",
        "\n",
        "    \n",
        "    encoder_vector = K.sum(encoder_vector, axis=1)\n",
        "\n",
        "    '''For luong_score expanded the last dimension to accommodate the hidden_size dimension of the encoder_outputs, so after the expansion, \n",
        "    the shape becomes [batch_size, max_source_sent_len, max_target_sent_len, 1]. For encoder_outputs the target shape is [batch_size, max_source_sent_len, 1, hidden_size]. \n",
        "    When multiply between the two tensors, the expanded dimensions will be broadcasted so that they have the same shape. \n",
        "    Summed the max_source_sent_len dimension to create the encoder_vector. \n",
        "    '''\n",
        "    \n",
        "    \"\"\"\n",
        "    End Task 3\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js7n4ou_KlUH",
        "outputId": "3aac3040-16ef-4491-a99a-407bbc816c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dictionaries\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 100)    203400      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, None, 100)    0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 100)    250600      ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 200),  240800      ['dropout_2[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, None, 100)    0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 200),  240800      ['dropout_3[0][0]',              \n",
            "                                 (None, 200),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 200)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  (None, None, 400)   0           ['lstm_2[0][0]',                 \n",
            " r)                                                               'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 2506)   1004906     ['attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,940,506\n",
            "Trainable params: 1,940,506\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         203400    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 100)         0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 444,200\n",
            "Trainable params: 444,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 100)    250600      ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, None, 100)    0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, None, 200)]  0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 200),  240800      ['dropout_3[0][0]',              \n",
            "                                 (None, 200),                     'input_8[0][0]',                \n",
            "                                 (None, 200)]                     'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer_1 (AttentionLa  (None, None, 400)   0           ['input_10[0][0]',               \n",
            " yer)                                                             'lstm_3[1][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 2506)   1004906     ['attention_layer_1[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,496,306\n",
            "Trainable params: 1,496,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 51s 193ms/step - loss: 2.0608 - accuracy: 0.2672\n",
            "Time used for epoch 1: 1 m 26 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "The input sentence:  ['it', '&apos;s', 'a', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 4.66\n",
            "Time used for evaluate on dev set: 0 m 9 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 46s 192ms/step - loss: 1.5788 - accuracy: 0.3959\n",
            "Time used for epoch 2: 1 m 21 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "The input sentence:  ['there', '&apos;s', 'a', '<unk>', ',', 'the', '<unk>', ',', 'the', '<unk>', ',', 'it', '&apos;s', 'a', '<unk>', ',', 'it', '&apos;s', 'a', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 10.10\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 46s 191ms/step - loss: 1.3266 - accuracy: 0.4526\n",
            "Time used for epoch 3: 1 m 21 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', '<unk>', ',', 'to', 'go', 'back', 'to', 'each', 'time', ',', 'it', '&apos;s', '<unk>', ',', 'it', '&apos;s', '<unk>', 'to', 'the', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 12.88\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 46s 192ms/step - loss: 1.1863 - accuracy: 0.4824\n",
            "Time used for epoch 4: 1 m 21 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', 'things', 'that', 'controls', ',', 'for', 'every', 'time', ',', 'it', 'was', '<unk>', 'when', 'it', 'comes', 'through', 'the', 'back', 'of', 'the', 'back', 'of', 'the', 'back', 'of', 'the', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 13.73\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 46s 192ms/step - loss: 1.0990 - accuracy: 0.5022\n",
            "Time used for epoch 5: 1 m 21 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', 'things', 'that', '<unk>', ',', 'to', 'control', 'the', '<unk>', ',', 'it', 'was', '<unk>', ',', 'it', '&apos;s', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 14.19\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 46s 192ms/step - loss: 1.0395 - accuracy: 0.5169\n",
            "Time used for epoch 6: 0 m 46 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', '<unk>', ',', 'to', 'grab', 'this', '<unk>', ',', 'it', '&apos;s', 'going', 'to', 'go', 'back', 'to', 'this', 'picture', ',', 'it', '&apos;s', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 15.21\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 47s 194ms/step - loss: 0.9925 - accuracy: 0.5291\n",
            "Time used for epoch 7: 1 m 21 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', 'things', 'that', '<unk>', ',', 'to', 'every', 'time', ',', 'it', '&apos;s', 'when', 'it', 'goes', 'through', 'the', 'mirror', ',', 'it', '&apos;s', '<unk>', 'shaped', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 15.10\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 46s 190ms/step - loss: 0.9566 - accuracy: 0.5380\n",
            "Time used for epoch 8: 1 m 21 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', '<unk>', '<unk>', ',', 'to', 'spend', 'it', 'back', ',', 'it', 'runs', 'back', ',', 'it', '&apos;s', 'going', 'to', 'go', 'through', 'it', ',', 'it', 'runs', 'off', 'the', 'mirror', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 14.87\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 46s 191ms/step - loss: 0.9260 - accuracy: 0.5473\n",
            "Time used for epoch 9: 1 m 21 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', '<unk>', '<unk>', ',', 'for', 'each', 'time', ',', 'it', '&apos;s', '<unk>', ',', 'it', '&apos;s', '<unk>', ',', 'it', '&apos;s', '<unk>', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 15.07\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 45s 189ms/step - loss: 0.9049 - accuracy: 0.5537\n",
            "Time used for epoch 10: 1 m 21 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "The input sentence:  ['there', '&apos;s', 'four', 'o', '&apos;clock', ',', 'to', 'grab', 'every', 'time', ',', 'it', 'went', 'next', 'time', ',', 'it', 'went', 'to', 'the', 'mirror', 'image', ',', 'it', '&apos;s', 'the', '<unk>', 'mirror', '.']\n",
            "The output sentence:  [['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']]\n",
            "source_words: [['có', '4', 'vi', 'điều', 'khiển', ',', 'để', 'mỗi', 'lần', 'vòng', 'này', 'quay', 'khi', 'nó', 'qua', 'phía', 'sau', 'hình', 'ảnh', ',', 'nó', 'ghi', 'nhận', 'dấu', 'hiệu', 'vị', 'trí', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 15.15\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Training finished!\n",
            "Time used for training: 14 m 33 s\n",
            "Evaluating on test set:\n",
            "The input sentence:  ['the', 'fourth', 'best', 'funded', 'is', 'from', 'the', 'first', '<unk>', 'of', 'the', '<unk>', '<unk>', 'of', 'the', '<unk>', 'language', '.']\n",
            "The output sentence:  [['the', 'second', 'quote', 'is', 'from', 'the', 'head', 'of', 'the', 'u.k.', 'financial', 'services', '<unk>', '.']]\n",
            "source_words: [['trích', 'dẫn', 'thứ', 'hai', 'đến', 'từ', 'người', 'đứng', 'đầu', 'cơ', 'quan', 'quản', 'lý', 'dịch', 'vụ', 'tài', 'chính', 'vương', 'quốc', 'anh', '.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
            "Model BLEU score: 15.27\n",
            "Time used for evaluate on test set: 0 m 8 s\n"
          ]
        }
      ],
      "source": [
        "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oUOUAjLYpCMk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Lab5_6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}